# Check https://circleci.com/docs/2.0/language-python/ for more details
version: 2.1

executors:
  venv_tester:
    working_directory: ~/repo
    parameters:
      tag:
        type: string
        default: "3.10"
    docker:
      - image: cimg/python:<< parameters.tag >>
        auth:
          username: $DOCKER_USER
          password: $DOCKER_PASS
    resource_class: large
  conda_tester:
    working_directory: ~/repo
    docker:
      - image: cimg/base:2021.04
        auth:
          username: $DOCKER_USER
          password: $DOCKER_PASS
    resource_class: large
  publisher:
    working_directory: ~/repo
    docker:
      - image: cimg/python:3.10
        auth:
          username: $DOCKER_USER
          password: $DOCKER_PASS
    environment:
      PYENV: "py310"
  tweeter:
    working_directory: ~/repo
    parameters:
      tag:
        type: string
        default: "3.10"
      pyenv:
        type: string
        default: "py310"
    docker:
      - image: cimg/python:<< parameters.tag >>
        auth:
          username: $DOCKER_USER
          password: $DOCKER_PASS
    environment:
      PYENV: << parameters.pyenv >>
  gh_releaser:
    working_directory: ~/repo
    docker:
      - image: cimg/base:2021.04
        auth:
          username: $DOCKER_USER
          password: $DOCKER_PASS

workflows:

  check_for_upgraded_deps:
    when:
      and:
        - equal: [ scheduled_pipeline, << pipeline.trigger_source >> ]
        - equal: [ "Recompile and test deps", << pipeline.schedule.name >> ]
    jobs:
      - test_with_updated_deps:
          name: "test_with_updated_deps_py38"
          tag: "3.8"
          toxenvs: "py38"
          context:
            - Docker pulling as bludoc
      - test_with_updated_deps:
          name: "test_with_updated_deps_py39"
          tag: "3.9"
          toxenvs: "py39"
          context:
            - Docker pulling as bludoc
      - test_with_updated_deps:
          name: "test_with_updated_deps_py310"
          tag: "3.10"
          toxenvs: "py310"
          context:
            - Docker pulling as bludoc
      - test_with_updated_deps:
          name: "test_with_updated_deps_py311"
          tag: "3.11"
          toxenvs: "py311"
          context:
            - Docker pulling as bludoc
      - commit_push_open_pr:
          requires:
            - test_with_updated_deps_py38
            - test_with_updated_deps_py39
            - test_with_updated_deps_py310
            - test_with_updated_deps_py311
          context:
            - Docker pulling as bludoc
            - GitHub pushes to BjoernLudwigPTB's public_repos

  nightly_test:
    when:
      and:
        - equal: [ scheduled_pipeline, << pipeline.trigger_source >> ]
        - equal: [ "Weekly nightly tests", << pipeline.schedule.name >> ]
    jobs:
      - test:
          name: "nightly_test_python_py38"
          tag: "3.8"
          toxenvs: "py38 -e py38-without_requirements"
          context:
            - Docker pulling as bludoc
      - test:
          name: "nightly_test_python_py39"
          tag: "3.9"
          toxenvs: "py39 -e py39-without_requirements"
          context:
            - Docker pulling as bludoc
      - test:
          name: "nightly_test_python_py310"
          tag: "3.10"
          toxenvs: "py310 -e py310-without_requirements"
          context:
            - Docker pulling as bludoc
      - test:
          name: "nightly_test_python_py311"
          tag: "3.11"
          toxenvs: "py311 -e py311-without_requirements"
          context:
            - Docker pulling as bludoc
      - test_conda_py39:
          context:
            - Docker pulling as bludoc

  quick_test:
    when:
      not:
        equal: [ scheduled_pipeline, << pipeline.trigger_source >> ]
    jobs:
      - test:
          tag: "3.10"
          toxenvs: "py310-without_requirements"
          posargs: "-m 'not slow'"
          parallelism: 4
          context:
            - Docker pulling as bludoc

  test_and_deploy:
    when:
      not:
        equal: [ scheduled_pipeline, << pipeline.trigger_source >> ]
    jobs:
      - test:
          name: "test_python_py38"
          tag: "3.8"
          toxenvs: "py38-without_requirements"
          context:
            - Docker pulling as bludoc
      - test:
          name: "test_python_py39"
          tag: "3.9"
          toxenvs: "py39-without_requirements"
          context:
            - Docker pulling as bludoc
      - test:
          name: "test_python_py310"
          tag: "3.10"
          toxenvs: "py310-without_requirements"
          context:
            - Docker pulling as bludoc
      - test:
          name: "test_python_py311"
          tag: "3.11"
          toxenvs: "py311-without_requirements"
          context:
            - Docker pulling as bludoc
      - test_conda_py39:
          context:
            - Docker pulling as bludoc
      - preview_release:
          requires:
            - test_python_py38
            - test_python_py39
            - test_python_py310
            - test_python_py311
            - test_conda_py39
          filters:
            branches:
              ignore: /.*dev$/
          context:
            - Docker pulling as bludoc
      - confirm_previewed_release_actions:
          # This job allows for checking that the release we will create in the
          # next step actually is the desired release, by observing the result of
          # preview_release.
          type: approval
          requires:
            - preview_release
          filters:
            branches:
              only: /main/
          context:
            - Docker pulling as bludoc
      - release:
          # Job to potentially create a release based on python-semantic-release's
          # decision and publish it on GitHub, Zenodo and PyPI.org. This requires manual
          # approval in the previous step, which is only triggered on branch main,
          # thus this job here is triggered only on main as well.
          context:
            - pypi.org publishing for PyDynamic
            - GitHub pushes to BjoernLudwigPTB's public_repos
            - Docker pulling as bludoc
          requires:
            - confirm_previewed_release_actions
      - tweet:
          context:
            - Twitter.com publish release
            - Docker pulling as bludoc
          requires:
            - release

commands:
  create_result_folder:
    description: "Checkout code and prepare test results location."
    steps:
    - checkout
    - run:
        name: Create test result folder
        command: |
          mkdir test-results

  create_venv:
    description: "Prepare virtual environment."
    steps:
    - run:
        name: Create virtual environment
        command: |
          python3 -m venv venv
          source venv/bin/activate
          python -m pip install --upgrade pip

  split_tests:
    description: "Split tests for shared execution."
    steps:
    - run:
        name: Split tests for shared execution
        command: |
          set -e
          echo 'export TEST_FILES=$(circleci tests glob "test/**/test_*.py" | \
            circleci tests split --split-by=timings)' >> $BASH_ENV

  install_development_deps:
    description: "Install development dependencies."
    parameters:
      pyenv:
        type: string
        default: "py310"
    steps:

    - run:
        name: Install development dependencies
        command: |
          source venv/bin/activate
          pip install -r requirements/dev-requirements-<< parameters.pyenv >>.txt

  tox:
    description: "Perform tox testing."
    parameters:
      toxenvs:
        type: string
        default: ""
      posargs:
        type: string
        default: ""
      tests:
        type: string
        default: ""
    steps:

    - run:
        name: Perform tox testing
        no_output_timeout: 60m
        command: |
          source venv/bin/activate
          tox -e << parameters.toxenvs >> -- << parameters.posargs >> \
            << parameters.tests >>

  store_results:
    description: "Store test results."
    steps:
    - store_test_results:
        path: test-results

  check_for_new_deps_compilation:
    description: "Check for new deps' compilation."
    steps:
    - run:
        name: Abort if no new deps were compiled
        command: |
          git add .
          set +e
          git status | grep modified
          if [ $? -ne 0 ]; then
              set -e
              echo "No updated deps. Nothing to test and commit. We are all good."
              circleci-agent step halt
          fi

jobs:

  test_with_updated_deps:
    parameters:
      tag:
        type: string
        default: "3.10"
      toxenvs:
        type: string
        default: "py310"
      posargs:
        type: string
        default: ""

    parallelism: 16

    executor:
      name: venv_tester
      tag: << parameters.tag >>

    steps:
      - create_result_folder
      - create_venv
      - run:
          name: Recompile and sync deps
          command: |
            source venv/bin/activate
            python -m pip install --upgrade tox pip-tools
            python -m piptools compile --upgrade \
              --output-file requirements/requirements-<< parameters.toxenvs >>.txt
            python -m piptools compile --upgrade \
              requirements/dev-requirements-<< parameters.toxenvs >>.in \
              --output-file requirements/dev-requirements-<< parameters.toxenvs >>.txt
            python -m piptools sync \
              requirements/requirements-<< parameters.toxenvs >>.txt \
              requirements/dev-requirements-<< parameters.toxenvs >>.txt
      - check_for_new_deps_compilation
      - split_tests
      - tox:
          toxenvs: << parameters.toxenvs >>
          tests: ${TEST_FILES}
      - store_results

      - persist_to_workspace:
          root: .
          paths:
            - requirements/requirements-<< parameters.toxenvs >>.txt
            - requirements/dev-requirements-<< parameters.toxenvs >>.txt

  commit_push_open_pr:
    executor:
      name: gh_releaser

    steps:
      - checkout
      - attach_workspace:
          at: .
      - check_for_new_deps_compilation
      - run:
          name: Set new branch name to 'recompile_deps'
          command: echo 'export NEW_BRANCH=recompile_deps' >> $BASH_ENV
      - run:
          name: Create and checkout new branch if not already on and add changes
          command: |
            if [ ${NEW_BRANCH} != ${CIRCLE_BRANCH} ]; then
                git checkout -b ${NEW_BRANCH}
            fi
      - run:
          name: Commit and push changes
          command: |
            git config --global user.name "Bjoern Ludwig (via CircleCI)"
            git config --global user.email "bjoern.ludwig@ptb.de"
            git commit -am \
              "build(deps): recompile Python (dev) deps on $(date)"
            git push -fu origin  ${NEW_BRANCH}
      - run:
          name: Install GitHub CLI
          command: |
            curl -fsSL \
              https://cli.github.com/packages/githubcli-archive-keyring.gpg |\
              sudo dd of=/etc/apt/trusted.gpg.d/githubcli-archive-keyring.gpg
            echo "deb [arch=$(dpkg --print-architecture) \
              signed-by=/etc/apt/trusted.gpg.d/githubcli-archive-keyring.gpg]\
              https://cli.github.com/packages stable main" | \
              sudo tee /etc/apt/sources.list.d/github-cli.list > /dev/null
            sudo apt update
            sudo apt install gh
      - run:
          name: Check for an existing PR or create one
          command: |
            set +e
            gh pr list --head=$NEW_BRANCH | grep $NEW_BRANCH
            if [ $? -eq 1 ]; then
                set -e
                gh pr create --base=main --title "Update deps" \
                  --body "This PR provides recompiled deps for all outdated \
                  package versions. It was opened after the committed deps \
                  were successfully compiled and all tests passed with the \
                  new versions. It should be merged as soon as possible to \
                  avoid any security issues due to outdated dependencies."
            else
                set -e
                echo "There already was a PR opened earlier. The 
                  current changes were force pushed into the existing branch."
            fi

  # Define one 'test' job with parameters to deal with all desired cases. The
  # reason for this is the desire to ensure the following for all supported Python
  # versions referring to the docs:
  #
  # - all tests are guaranteed to pass
  # - PyDynamic with respect to its `setup.py` successfully installs
  test:
    # Define all parameters, where 'tag' is used for the docker image and 'toxenvs' is
    # the string which is used in tox to identify the desired entries of envlist.
    # 'posargs' will be handed over to the commands of tox step. We use this to
    # extend the default test suite execution from only those tests not marked with
    # 'slow' to all tests during the nightly scheduled pipeline runs.
    parameters:
      tag:
        type: string
        default: "3.10"
      toxenvs:
        type: string
        default: ""
      posargs:
        type: string
        default: ""
      parallelism:
        type: integer
        default: 16

    parallelism: << parameters.parallelism >>

    executor:
      name: venv_tester
      tag: << parameters.tag >>

    steps:
      - create_result_folder
      - create_venv
      - run:
          name: Install tox
          command: |
            source venv/bin/activate
            pip install tox
      - split_tests
      - tox:
          toxenvs: << parameters.toxenvs >>
          posargs: << parameters.posargs >>
          tests: ${TEST_FILES}
      - store_results

  test_conda_py39:
    parallelism: 16

    executor: conda_tester

    steps:
      - create_result_folder
      - run:
          name: Install Miniconda
          command: |
            wget "https://repo.anaconda.com/miniconda/\
            Miniconda3-latest-Linux-x86_64.sh" -O $HOME/miniconda.sh
            mkdir -p $HOME/.conda
            bash $HOME/miniconda.sh -b -p /home/circleci/conda
            source $HOME/conda/etc/profile.d/conda.sh
            hash -r
            conda config --set always_yes yes --set changeps1 no
            conda update -q conda
            echo 'export PATH=$HOME/conda/bin:$PATH' >> $BASH_ENV

      - restore_cache:
          keys:
            - v4-conda-dependencies-{{ checksum "requirements/environment.yml" }}-{{ checksum "requirements/requirements.txt" }}
            - v4-conda-dependencies-

      - run:
          name: Create or update environment
          command: |
            if [ -d "$HOME/conda/envs/" ]; then
                conda env update --prune --file requirements/environment.yml
            else
                conda env create -f requirements/environment.yml
            fi
            source $HOME/conda/etc/profile.d/conda.sh
            conda activate PyDynamic_conda_env
            conda install pytest pytest-cov
            pip install --upgrade pytest-custom-exit-code hypothesis

      - save_cache:
          paths:
            - /home/circleci/conda/envs/
          key: >-
            v4-conda-dependencies-{{ checksum "requirements/environment.yml" }}-{{ checksum "requirements/requirements.txt" }}

      - split_tests

      - run:
          name: Run tests
          no_output_timeout: 60m
          command: |
            source $HOME/conda/etc/profile.d/conda.sh
            conda activate PyDynamic_conda_env
            pytest --cov=PyDynamic --junitxml=test-results/junit.xml \
              --suppress-no-test-exit-code ${TEST_FILES}
      - run:
          name: Upload coverage report
          command: |
            curl https://keybase.io/codecovsecurity/pgp_keys.asc | gpg --import
            curl -Os https://uploader.codecov.io/latest/linux/codecov
            curl -Os https://uploader.codecov.io/latest/linux/codecov.SHA256SUM
            curl -Os \
              https://uploader.codecov.io/latest/linux/codecov.SHA256SUM.sig
            gpg --verify codecov.SHA256SUM.sig codecov.SHA256SUM
            shasum -a 256 -c codecov.SHA256SUM
            chmod +x codecov
            ./codecov

      - store_results

  release:
    executor:
      name: publisher

    steps:
      - create_result_folder
      - create_venv
      - install_development_deps:
          pyenv: ${PYENV}

      - run:
          name: Run semantic-release publish
          command: |
            source venv/bin/activate
            git config --global user.name "semantic-release (via CircleCI)"
            git config --global user.email "bjoern.ludwig@ptb.de"
            semantic-release publish

  preview_release:
    executor:
      name: publisher

    steps:
      - create_result_folder
      - create_venv
      - install_development_deps:
          pyenv: ${PYENV}

      - run:
          name: Generate file with tweet's content
          command: |
            source venv/bin/activate
            new_version=$(semantic-release print-version)
            if [ -z $new_version ]; then
              rm -f tweet.txt
              touch tweet.txt
            else
              echo "The generated tweet will be:"
              echo "#PyDynamic "$new_version" just got released by \
                  #PhysikalischTechnischeBundesanstalt! \
                  Find out more about propagation \
                  of #measurementuncertainty in #dynamicmeasurements on \
                  https://github.com/PTB-M4D/PyDynamic/" \
                  | tr -s ' ' | tee tweet.txt
            fi

      - persist_to_workspace:
          root: .
          paths:
            - tweet.txt

      - run:
          name: Preview python-semantic-release actions
          command: |
            unset CIRCLE_PULL_REQUEST CIRCLE_PULL_REQUESTS CI_PULL_REQUEST \
              CI_PULL_REQUESTS
            export CIRCLE_BRANCH=main
            source venv/bin/activate
            git config --global user.name "semantic-release (via CircleCI)"
            git config --global user.email "bjoern.ludwig@ptb.de"
            echo "
            The changelog of the next release will contain:
            "
            semantic-release --unreleased changelog
            echo "
            -----------------------------------------------------------

            python-semantic-release would perform the following actions:
            "
            semantic-release --noop publish

  tweet:
    executor:
      name: tweeter
    steps:
      - checkout
      - attach_workspace:
          at: .

      - create_venv
      - install_development_deps:
          pyenv: ${PYENV}
      - run:
          name: Tweet on new releases
          command: |
            if [[ -s tweet.txt ]]; then
              source venv/bin/activate
              python setup.py tweet
            fi
